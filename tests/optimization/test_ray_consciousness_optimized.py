#!/usr/bin/env python3
"""
Optimized Ray Consciousness Test
Tests with realistic workloads and optimized batch sizes
"""

import time
import logging
import asyncio
import ray
from typing import Dict, List, Any
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Mock neural_darwinism module with more realistic processing
class MockNeuralDarwinism:
    """Mock implementation with realistic consciousness processing time"""
    
    @staticmethod
    def process_consciousness(data: Dict[str, Any]) -> Dict[str, Any]:
        # Simulate more realistic neural processing (50-100ms per consciousness event)
        base_time = 0.076  # 76ms baseline from our analysis
        variation = 0.024 * (hash(str(data)) % 100) / 100  # Add some variation
        time.sleep(base_time + variation)
        
        return {
            "processed_data": data,
            "consciousness_level": 0.85 + (hash(str(data)) % 30) / 100,
            "neural_activity": "high",
            "processing_time_ms": (base_time + variation) * 1000,
            "timestamp": time.time()
        }

# Initialize Ray with optimized settings
try:
    ray.init(
        num_cpus=4,
        object_store_memory=1000000000,  # 1GB object store
        ignore_reinit_error=True,
        configure_logging=False  # Reduce logging overhead
    )
    logger.info("‚úÖ Ray initialized with optimized settings")
except Exception as e:
    logger.error(f"‚ùå Failed to initialize Ray: {e}")
    exit(1)

@ray.remote
class OptimizedConsciousnessWorker:
    """Optimized Ray remote worker for consciousness processing"""
    
    def __init__(self, worker_id: int):
        self.worker_id = worker_id
        self.neural_engine = MockNeuralDarwinism()
        self.processed_count = 0
        logger.info(f"üß† Optimized Worker {worker_id} ready")
    
    def process_consciousness_batch(self, batch_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Process batch with better error handling and metrics"""
        start_time = time.time()
        results = []
        total_neural_time = 0
        
        for data in batch_data:
            data["worker_id"] = self.worker_id
            neural_start = time.time()
            result = self.neural_engine.process_consciousness(data)
            total_neural_time += (time.time() - neural_start) * 1000
            results.append(result)
            self.processed_count += 1
        
        total_time = (time.time() - start_time) * 1000
        
        return {
            "results": results,
            "worker_id": self.worker_id,
            "batch_size": len(batch_data),
            "total_time_ms": total_time,
            "neural_processing_time_ms": total_neural_time,
            "overhead_ms": total_time - total_neural_time,
            "throughput": len(batch_data) / (total_time / 1000)
        }
    
    def get_stats(self) -> Dict[str, Any]:
        return {
            "worker_id": self.worker_id,
            "processed_count": self.processed_count,
            "status": "active"
        }

class OptimizedRayConsciousness:
    """Optimized distributed consciousness processing"""
    
    def __init__(self, num_workers: int = 4):
        self.num_workers = num_workers
        self.workers = []
        self.stats = {
            "total_processed": 0,
            "total_batches": 0,
            "start_time": time.time()
        }
        
        # Initialize workers
        for i in range(num_workers):
            worker = OptimizedConsciousnessWorker.remote(i)
            self.workers.append(worker)
        
        logger.info(f"üöÄ Optimized Ray Consciousness ready with {num_workers} workers")
    
    async def process_large_batch(self, data_batch: List[Dict[str, Any]], 
                                  optimal_chunk_size: int = 25) -> Dict[str, Any]:
        """Process large batch with optimal chunking"""
        start_time = time.time()
        
        # Create optimal chunks
        chunks = [data_batch[i:i + optimal_chunk_size] 
                 for i in range(0, len(data_batch), optimal_chunk_size)]
        
        # Submit all chunks to workers in round-robin fashion
        futures = []
        for i, chunk in enumerate(chunks):
            worker_idx = i % len(self.workers)
            future = self.workers[worker_idx].process_consciousness_batch.remote(chunk)
            futures.append(future)
        
        # Collect results
        batch_results = ray.get(futures)
        
        # Aggregate results
        all_results = []
        total_neural_time = 0
        total_overhead = 0
        
        for batch_result in batch_results:
            all_results.extend(batch_result["results"])
            total_neural_time += batch_result["neural_processing_time_ms"]
            total_overhead += batch_result["overhead_ms"]
        
        total_time = (time.time() - start_time) * 1000
        
        self.stats["total_processed"] += len(data_batch)
        self.stats["total_batches"] += 1
        
        return {
            "results": all_results,
            "total_time_ms": total_time,
            "neural_processing_time_ms": total_neural_time,
            "overhead_ms": total_overhead,
            "items_processed": len(data_batch),
            "chunks_used": len(chunks),
            "workers_used": min(len(chunks), len(self.workers)),
            "avg_time_per_item": total_time / len(data_batch),
            "throughput": len(data_batch) / (total_time / 1000),
            "efficiency": (total_neural_time / total_time) * 100
        }

def sequential_processing_benchmark(data_batch: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Benchmark sequential processing for comparison"""
    start_time = time.time()
    neural_engine = MockNeuralDarwinism()
    results = []
    
    for data in data_batch:
        result = neural_engine.process_consciousness(data)
        results.append(result)
    
    total_time = (time.time() - start_time) * 1000
    
    return {
        "results": results,
        "total_time_ms": total_time,
        "items_processed": len(data_batch),
        "avg_time_per_item": total_time / len(data_batch),
        "throughput": len(data_batch) / (total_time / 1000)
    }

async def comprehensive_performance_test():
    """Comprehensive performance test with realistic workloads"""
    logger.info("üî¨ Starting Comprehensive Ray Performance Test")
    
    # Test with different batch sizes
    test_sizes = [50, 100, 200, 500]  # Realistic consciousness event batches
    results = {}
    
    consciousness = OptimizedRayConsciousness(num_workers=4)
    
    for size in test_sizes:
        logger.info(f"üìä Testing with {size} consciousness events...")
        
        # Create test data
        test_data = []
        for i in range(size):
            test_data.append({
                "stimulus_id": f"consciousness_event_{i}",
                "neural_input": f"complex_neural_pattern_{i}",
                "context": {"priority": "high", "complexity": "adaptive"},
                "timestamp": time.time() + i * 0.001
            })
        
        # Test distributed processing
        distributed_result = await consciousness.process_large_batch(test_data)
        
        # Test sequential processing
        sequential_result = sequential_processing_benchmark(test_data[:20])  # Sample for comparison
        estimated_sequential = sequential_result["avg_time_per_item"] * size
        
        # Calculate improvement
        improvement = ((estimated_sequential - distributed_result["total_time_ms"]) / 
                      estimated_sequential) * 100
        
        results[size] = {
            "distributed_time": distributed_result["total_time_ms"],
            "estimated_sequential": estimated_sequential,
            "improvement_percent": improvement,
            "efficiency": distributed_result["efficiency"],
            "throughput": distributed_result["throughput"],
            "target_achieved": improvement >= 50
        }
        
        logger.info(f"   Size {size}: {improvement:.1f}% improvement, "
                   f"{distributed_result['efficiency']:.1f}% efficiency")
    
    return results

async def main():
    """Main optimized test execution"""
    try:
        logger.info("üöÄ Optimized Ray Distributed Consciousness Test")
        logger.info("=" * 60)
        
        # Run comprehensive test
        results = await comprehensive_performance_test()
        
        # Find best performing configuration
        best_size = max(results.keys(), key=lambda k: results[k]["improvement_percent"])
        best_result = results[best_size]
        
        logger.info("\nüéØ COMPREHENSIVE TEST RESULTS:")
        for size, result in results.items():
            status = "‚úÖ TARGET MET" if result["target_achieved"] else "‚ùå TARGET MISSED"
            logger.info(f"   Batch Size {size}: {result['improvement_percent']:.1f}% improvement - {status}")
        
        logger.info(f"\nüèÜ BEST PERFORMANCE:")
        logger.info(f"   Optimal Batch Size: {best_size} events")
        logger.info(f"   Performance Improvement: {best_result['improvement_percent']:.1f}%")
        logger.info(f"   System Efficiency: {best_result['efficiency']:.1f}%")
        logger.info(f"   Throughput: {best_result['throughput']:.1f} events/second")
        
        overall_success = any(r["target_achieved"] for r in results.values())
        logger.info(f"\n‚ú® RAY INTEGRATION STATUS: {'‚úÖ SUCCESS' if overall_success else '‚ùå NEEDS WORK'}")
        
        return results
        
    except Exception as e:
        logger.error(f"‚ùå Test failed: {e}")
        return None
    finally:
        ray.shutdown()
        logger.info("üîÑ Ray cluster shut down")

if __name__ == "__main__":
    results = asyncio.run(main())
    
    if results:
        success_count = sum(1 for r in results.values() if r["target_achieved"])
        print(f"\nüéâ RAY CONSCIOUSNESS INTEGRATION RESULTS:")
        print(f"‚úÖ {success_count}/{len(results)} test configurations achieved 50%+ improvement")
        
        if success_count > 0:
            print("üöÄ Ready for production deployment with optimal batch sizing!")
        else:
            print("üîß Functional but requires workload optimization for target performance")
    else:
        print("\n‚ùå Test execution failed")
